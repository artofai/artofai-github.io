<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on The Art of Artificial Intelligence</title>
    <link>http://artofai.github.io/posts/</link>
    <description>Recent content in Posts on The Art of Artificial Intelligence</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 28 Feb 2021 15:47:38 +0100</lastBuildDate><atom:link href="http://artofai.github.io/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Language Models 02</title>
      <link>http://artofai.github.io/posts/language-models-02/</link>
      <pubDate>Sun, 28 Feb 2021 15:47:38 +0100</pubDate>
      
      <guid>http://artofai.github.io/posts/language-models-02/</guid>
      <description>We start the implementation with dataset exploratory analysis and project template.
Project template If you want to code along (I strongly reccomend such aproach) you can use any project template you like. The template I will use is following:
Going top-down:
 char_lm - Directory with model&amp;rsquo;s package data - All data. It contains multiple subdirectories  raw - Data as downloaded/scrapped/extracted. Read only, no manual manipulations allowed! interim - Intermediate formats - after prerocessing etc dataset - Datasets after preparatons, ready to be used by models.</description>
    </item>
    
    <item>
      <title>Language Models 01</title>
      <link>http://artofai.github.io/posts/language-models-01/</link>
      <pubDate>Sun, 14 Feb 2021 12:56:09 +0100</pubDate>
      
      <guid>http://artofai.github.io/posts/language-models-01/</guid>
      <description>If there is one single topic I could reccomend to learn for every person learning NLP - that would be language models.
Chances that you will need to implement a LM in your work are very small. But concepts you can learn are priceless. A lot of NLP topics like sequence to sequence models, machine translation, summarization - or even famous transformer models are built on top of lanaguage models. Of course they also have some direct applications.</description>
    </item>
    
  </channel>
</rss>
